# Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ

> –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –æ—Ç inbox –¥–æ –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ë–ó 2.0.

## –û–±–∑–æ—Ä Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      VIDEO PROCESSING PIPELINE                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ 1.PARSE ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ2.WHISPER‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ3.CLEAN  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ4.CHUNK  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ filename‚îÇ    ‚îÇtranscr. ‚îÇ    ‚îÇ + gloss ‚îÇ    ‚îÇsemantic ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                   ‚îÇ             ‚îÇ
‚îÇ                                                   ‚ñº             ‚îÇ
‚îÇ                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ                              ‚îÇ6.SAVE   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ5.SUMMAR.‚îÇ         ‚îÇ
‚îÇ                              ‚îÇ files   ‚îÇ    ‚îÇ + class ‚îÇ         ‚îÇ
‚îÇ                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–∞–ø–æ–≤

| –≠—Ç–∞–ø | –ù–∞–∑–≤–∞–Ω–∏–µ | –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç | –í—Ö–æ–¥ | –í—ã—Ö–æ–¥ |
|------|----------|------------|------|-------|
| 1 | Parse Filename | Python regex | `*.mp4` filename | `VideoMetadata` |
| 2 | Transcribe | faster-whisper | `*.mp4` file | `RawTranscript` |
| 3 | Clean | Ollama + Glossary | `RawTranscript` | `CleanedTranscript` |
| 4 | Chunk | Ollama | `CleanedTranscript` | `TranscriptChunks` |
| 5 | Summarize | Ollama | `CleanedTranscript` | `Summary` + classification |
| 6 | Save | Python | All data | Files in archive |

---

## –≠—Ç–∞–ø 1: Parse Filename

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É.

### –ü–∞—Ç—Ç–µ—Ä–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞

```
{–¥–∞—Ç–∞} {—Ç–∏–ø}.{–ø–æ—Ç–æ–∫} {—Ç–µ–º–∞} ({—Å–ø–∏–∫–µ—Ä}).mp4

–ü—Ä–∏–º–µ—Ä:
2025.04.07 –ü–®.SV –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –ì—Ä—É–ø–ø—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (–°–≤–µ—Ç–ª–∞–Ω–∞ –î–º–∏—Ç—Ä—É–∫).mp4
```

### Regex

```python
FILENAME_PATTERN = r'^(\d{4}\.\d{2}\.\d{2})\s+(\w+)\.(\w+)\s+(.+?)\s+\(([^)]+)\)(?:\.\w+)?$'

# –ì—Ä—É–ø–ø—ã:
# 1: date       (2025.04.07)
# 2: event_type (–ü–®)
# 3: stream     (SV)
# 4: title      (–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –ì—Ä—É–ø–ø—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏)
# 5: speaker    (–°–≤–µ—Ç–ª–∞–Ω–∞ –î–º–∏—Ç—Ä—É–∫)
```

### –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö

```python
from dataclasses import dataclass
from datetime import date
from pathlib import Path

@dataclass
class VideoMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    
    # –ò–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    date: date                    # 2025-04-07
    event_type: str               # –ü–®
    stream: str                   # SV
    title: str                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –ì—Ä—É–ø–ø—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    speaker: str                  # –°–≤–µ—Ç–ª–∞–Ω–∞ –î–º–∏—Ç—Ä—É–∫
    
    # –í—ã—á–∏—Å–ª—è–µ–º—ã–µ
    original_filename: str        # –ü–æ–ª–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    video_id: str                 # 2025-04-07_psh-sv_gruppa-podderzhki
    
    # –ü—É—Ç–∏
    source_path: Path             # /inbox/filename.mp4
    archive_path: Path            # /archive/2025/04/–ü–®.SV/Title (Speaker)/
    
    @property
    def stream_full(self) -> str:
        """–ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ –∏–∑ config/events.yaml."""
        # –ü–®.SV -> –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏—á–Ω–∞—è –®–∫–æ–ª–∞ ‚Äî –°—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä—ã
        pass
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è video_id

```python
def generate_video_id(metadata: VideoMetadata) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –≤–∏–¥–µ–æ.
    
    –§–æ—Ä–º–∞—Ç: {date}_{event_type}-{stream}_{slug}
    –ü—Ä–∏–º–µ—Ä: 2025-04-07_psh-sv_gruppa-podderzhki
    """
    date_str = metadata.date.isoformat()  # 2025-04-07
    event_stream = f"{metadata.event_type}-{metadata.stream}".lower()  # psh-sv
    slug = slugify(metadata.title)  # gruppa-podderzhki
    
    return f"{date_str}_{event_stream}_{slug}"
```

### Error Handling

```python
class FilenameParseError(Exception):
    """–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É."""
    pass

def parse_filename(filename: str) -> VideoMetadata:
    match = re.match(FILENAME_PATTERN, filename)
    if not match:
        raise FilenameParseError(
            f"–§–∞–π–ª '{filename}' –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É. "
            f"–û–∂–∏–¥–∞–µ—Ç—Å—è: '{{–¥–∞—Ç–∞}} {{—Ç–∏–ø}}.{{–ø–æ—Ç–æ–∫}} {{—Ç–µ–º–∞}} ({{—Å–ø–∏–∫–µ—Ä}}).mp4'"
        )
    # ...
```

---

## –≠—Ç–∞–ø 2: Transcribe (Whisper)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤.

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç

**faster-whisper-server** ‚Äî REST API —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏, —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –Ω–∞ TrueNAS.

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| API URL | http://100.64.0.1:9000 |
| –ú–æ–¥–µ–ª—å | large-v3 (–ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–∞) |
| GPU | RTX 5070 Ti |

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
import requests

WHISPER_CONFIG = {
    "api_url": "http://100.64.0.1:9000",
    "language": "ru",              # –†—É—Å—Å–∫–∏–π —è–∑—ã–∫
    "response_format": "verbose_json",  # JSON —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
    "timeout": 600,                # 10 –º–∏–Ω—É—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ
}
````

### –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö

```python
@dataclass
class TranscriptSegment:
    """–û–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –æ—Ç Whisper."""
    
    start: float          # –ù–∞—á–∞–ª–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (15.5)
    end: float            # –ö–æ–Ω–µ—Ü –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (18.2)
    text: str             # –¢–µ–∫—Å—Ç —Å–µ–≥–º–µ–Ω—Ç–∞
    
    @property
    def start_time(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ (00:00:15)."""
        return self._format_time(self.start)
    
    @property
    def end_time(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –∫–æ–Ω—Ü–∞ (00:00:18)."""
        return self._format_time(self.end)
    
    @staticmethod
    def _format_time(seconds: float) -> str:
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"


@dataclass
class RawTranscript:
    """–°—ã—Ä–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –æ—Ç Whisper."""
    
    segments: list[TranscriptSegment]
    language: str                    # –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —è–∑—ã–∫
    duration_seconds: float          # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ
    whisper_model: str               # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    
    @property
    def full_text(self) -> str:
        """–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–∞–π–º-–∫–æ–¥–æ–≤."""
        return " ".join(seg.text for seg in self.segments)
    
    @property
    def text_with_timestamps(self) -> str:
        """–¢–µ–∫—Å—Ç —Å —Ç–∞–π–º-–∫–æ–¥–∞–º–∏ –¥–ª—è LLM –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        lines = []
        for seg in self.segments:
            lines.append(f"[{seg.start_time}] {seg.text}")
        return "\n".join(lines)
```

### –ü—Ä–æ—Ü–µ—Å—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

```python
import requests
from pathlib import Path

async def transcribe(video_path: Path, config: dict) -> RawTranscript:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Whisper HTTP API.
    
    1. –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –Ω–∞ —Å–µ—Ä–≤–µ—Ä faster-whisper
    2. –ü–æ–ª—É—á–∞–µ—Ç JSON —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    3. –°–æ–±–∏—Ä–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ RawTranscript
    """
    
    url = f"{config['api_url']}/v1/audio/transcriptions"
    
    with open(video_path, "rb") as f:
        response = requests.post(
            url,
            files={"file": f},
            data={
                "language": config["language"],
                "response_format": config["response_format"],
            },
            timeout=config["timeout"]
        )
    
    response.raise_for_status()
    data = response.json()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ API
    transcript_segments = [
        TranscriptSegment(
            start=seg["start"],
            end=seg["end"],
            text=seg["text"].strip()
        )
        for seg in data.get("segments", [])
    ]
    
    return RawTranscript(
        segments=transcript_segments,
        language=data.get("language", config["language"]),
        duration_seconds=data.get("duration", 0),
        whisper_model="large-v3"
    )
```

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤

```python
async def transcribe_text_only(video_path: Path, config: dict) -> str:
    """
    –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è ‚Äî —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–∞–π–º–∫–æ–¥–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω—É–∂–Ω—ã.
    """
    
    url = f"{config['api_url']}/v1/audio/transcriptions"
    
    with open(video_path, "rb") as f:
        response = requests.post(
            url,
            files={"file": f},
            data={
                "language": config["language"],
                "response_format": "text",
            },
            timeout=config["timeout"]
        )
    
    response.raise_for_status()
    return response.text
```

### –ü—Ä–æ–≥—Ä–µ—Å—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

```python
# WebSocket updates –¥–ª—è UI
async def transcribe_with_progress(
    video_path: Path,
    config: dict,
    progress_callback: Callable[[float, str], None]
) -> RawTranscript:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
    
    progress_callback(percent, status_message)
    
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: Whisper API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
    –ü—Ä–æ–≥—Ä–µ—Å—Å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –ø–æ —ç—Ç–∞–ø–∞–º: –æ—Ç–ø—Ä–∞–≤–∫–∞ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –≥–æ—Ç–æ–≤–æ.
    """
    progress_callback(0, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞...")
    
    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞
    file_size_mb = video_path.stat().st_size / (1024 * 1024)
    estimated_seconds = file_size_mb * 0.5  # ~0.5 —Å–µ–∫ –Ω–∞ MB (—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)
    
    progress_callback(5, "–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä Whisper...")
    
    url = f"{config['api_url']}/v1/audio/transcriptions"
    
    with open(video_path, "rb") as f:
        progress_callback(10, f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (~{int(estimated_seconds)} —Å–µ–∫)...")
        
        response = requests.post(
            url,
            files={"file": f},
            data={
                "language": config["language"],
                "response_format": config["response_format"],
            },
            timeout=config["timeout"]
        )
    
    progress_callback(90, "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
    
    response.raise_for_status()
    data = response.json()
    
    transcript_segments = [
        TranscriptSegment(
            start=seg["start"],
            end=seg["end"],
            text=seg["text"].strip()
        )
        for seg in data.get("segments", [])
    ]
    
    progress_callback(100, "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    return RawTranscript(
        segments=transcript_segments,
        language=data.get("language", config["language"]),
        duration_seconds=data.get("duration", 0),
        whisper_model="large-v3"
    )
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞

```python
def check_whisper_available(config: dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ Whisper —Å–µ—Ä–≤–∏—Å –¥–æ—Å—Ç—É–ø–µ–Ω."""
    try:
        response = requests.get(
            f"{config['api_url']}/health",
            timeout=5
        )
        return response.text == "OK"
    except requests.RequestException:
        return False
```

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

|–ú–µ—Ç—Ä–∏–∫–∞|–ó–Ω–∞—á–µ–Ω–∏–µ|
|---|---|
|–ú–æ–¥–µ–ª—å|large-v3 (–ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ)|
|–ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –ø—Ä–æ—Å—Ç–æ—è|~65 —Å–µ–∫ (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ VRAM)|
|–ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã|~4-5 —Å–µ–∫ –Ω–∞ 15 —Å–µ–∫ –∞—É–¥–∏–æ|
|VRAM|~3.5 GB|
|–¢–∞–π–º–∞—É—Ç –º–æ–¥–µ–ª–∏|5 –º–∏–Ω –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏|

> **–í–∞–∂–Ω–æ:** –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –ø—Ä–æ—Å—Ç–æ—è —Å–µ—Ä–≤–µ—Ä–∞ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–º ‚Äî –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –≤ GPU –ø–∞–º—è—Ç—å. –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –±—ã—Å—Ç—Ä–æ.

---

## –≠—Ç–∞–ø 3: Clean (LLM + Glossary)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–û—á–∏—Å—Ç–∫–∞ —Å—ã—Ä–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –æ—Ç —à—É–º–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏.

### –ü—Ä–æ–±–ª–µ–º—ã —Å—ã—Ä–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞

| –ü—Ä–æ–±–ª–µ–º–∞ | –ü—Ä–∏–º–µ—Ä | –†–µ—à–µ–Ω–∏–µ |
|----------|--------|---------|
| –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã | "–Ω—É", "–≤–æ—Ç", "–∫–∞–∫ –±—ã", "—ç—ç—ç" | LLM —É–¥–∞–ª—è–µ—Ç |
| –û—Ç–≤–ª–µ—á–µ–Ω–∏—è | "–∫—Å—Ç–∞—Ç–∏, –≤—á–µ—Ä–∞ —è..." | LLM —É–¥–∞–ª—è–µ—Ç |
| –û—à–∏–±–∫–∏ Whisper | "–§–æ—Ä–º—É–ª–∞ –æ–¥–∏–Ω" | –ì–ª–æ—Å—Å–∞—Ä–∏–π –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç |
| –¢–µ—Ä–º–∏–Ω—ã Herbalife | "–≥–µ—Ä–±–∞–ª–∞–π—Ñ" | –ì–ª–æ—Å—Å–∞—Ä–∏–π –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç |

### –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞

```
RawTranscript
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3a. GLOSSARY    ‚îÇ  –ë—ã—Å—Ç—Ä–∞—è –∑–∞–º–µ–Ω–∞ –ø–æ —Å–ª–æ–≤–∞—Ä—é
‚îÇ    (Python)     ‚îÇ  
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3b. LLM CLEAN   ‚îÇ  –£–¥–∞–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–∑–∏—Ç–æ–≤ –∏ –æ—Ç–≤–ª–µ—á–µ–Ω–∏–π
‚îÇ    (Ollama)     ‚îÇ  
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
  CleanedTranscript
```

### 3a. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è

```python
import yaml
import re
from pathlib import Path

def load_glossary(path: Path = Path("config/glossary.yaml")) -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤."""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def apply_glossary(text: str, glossary: dict) -> str:
    """
    –ó–∞–º–µ–Ω—è–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ç–µ—Ä–º–∏–Ω–æ–≤ –Ω–∞ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é —Ñ–æ—Ä–º—É.
    
    –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω: —Å–Ω–∞—á–∞–ª–∞ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –ø–æ—Ç–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ.
    """
    replacements = []
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–º–µ–Ω—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    for category in glossary.values():
        for term in category:
            canonical = term["canonical"]
            for variation in term["variations"]:
                replacements.append((variation, canonical))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (–¥–ª–∏–Ω–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    replacements.sort(key=lambda x: len(x[0]), reverse=True)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
    for variation, canonical in replacements:
        # Regex —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ —Å–ª–æ–≤, —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
        pattern = rf'\b{re.escape(variation)}\b'
        text = re.sub(pattern, canonical, text, flags=re.IGNORECASE)
    
    return text
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ glossary.yaml

```yaml
# config/glossary.yaml

products:
  - canonical: "–§–æ—Ä–º—É–ª–∞ 1"
    variations:
      - "—Ñ–æ—Ä–º—É–ª–∞ –æ–¥–∏–Ω"
      - "—Ñ–æ—Ä–º—É–ª–∞ 1"
      - "–§1"
      - "—Ñ-1"
      - "formula 1"
      - "formula one"
  
  - canonical: "–§–æ—Ä–º—É–ª–∞ 2"
    variations:
      - "—Ñ–æ—Ä–º—É–ª–∞ –¥–≤–∞"
      - "—Ñ–æ—Ä–º—É–ª–∞ 2"
      - "–§2"
      - "—Ñ-2"
  
  - canonical: "–ü—Ä–æ—Ç–µ–∏–Ω–æ–≤–∞—è —Å–º–µ—Å—å"
    variations:
      - "–ø—Ä–æ—Ç–µ–∏–Ω –º–∏–∫—Å"
      - "–ø—Ä–æ—Ç–µ–∏–Ω —à–µ–π–∫"
      - "protein mix"
      - "–±–µ–ª–∫–æ–≤–∞—è —Å–º–µ—Å—å"

brand:
  - canonical: "Herbalife"
    variations:
      - "–≥–µ—Ä–±–∞–ª–∞–π—Ñ"
      - "–≥–µ—Ä–±–æ –ª–∞–π—Ñ"
      - "—Ö–µ—Ä–±–∞–ª–∞–π—Ñ"
      - "herbal life"
      - "—Ö–µ—Ä–±–∞ –ª–∞–π—Ñ"

business:
  - canonical: "–ì—Ä—É–ø–ø–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
    variations:
      - "–≥—Ä—É–ø–ø–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
      - "–≥–ø"
      - "–≥—Ä—É–ø–ø–æ–≤–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞"
  
  - canonical: "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏—á–Ω–∞—è –®–∫–æ–ª–∞"
    variations:
      - "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏—á–Ω–∞—è —à–∫–æ–ª–∞"
      - "–ø—à"
      - "—à–∫–æ–ª–∞ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞"
      - "monday school"

roles:
  - canonical: "–°—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä"
    variations:
      - "—Å—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä"
      - "—Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä"
      - "—Å–≤"
      - "supervisor"
  
  - canonical: "–ù–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–∞—Ä—Ç–Ω—ë—Ä"
    variations:
      - "–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–∞—Ä—Ç–Ω–µ—Ä"
      - "–Ω–ø"
      - "–ø–∞—Ä—Ç–Ω–µ—Ä"
      - "independent partner"
```

### 3b. LLM Clean (Ollama)

```python
from ollama import AsyncClient

LLM_CLEAN_CONFIG = {
    "model": "qwen2.5:14b",
    "temperature": 0.3,          # –ù–∏–∑–∫–∞—è –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    "num_ctx": 16384,            # –ë–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
}

async def llm_clean_transcript(
    text: str,
    metadata: VideoMetadata,
    client: AsyncClient
) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ LLM.
    
    –£–¥–∞–ª—è–µ—Ç:
    - –°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã
    - –û—Ç–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç —Ç–µ–º—ã
    - –ü–æ–≤—Ç–æ—Ä—ã –∏ –∑–∞–∏–∫–∞–Ω–∏—è
    
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
    - –í–µ—Å—å —Å–º—ã—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
    - –°—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑–ª–æ–∂–µ–Ω–∏—è
    """
    
    prompt = load_prompt("config/prompts/cleaner.md")
    prompt = prompt.format(
        title=metadata.title,
        speaker=metadata.speaker,
        transcript=text
    )
    
    response = await client.chat(
        model="qwen2.5:14b",
        messages=[{"role": "user", "content": prompt}],
        options={
            "temperature": LLM_CLEAN_CONFIG["temperature"],
            "num_ctx": LLM_CLEAN_CONFIG["num_ctx"],
        }
    )
    
    return response["message"]["content"]
```

### –ü—Ä–æ–º–ø—Ç –æ—á–∏—Å—Ç–∫–∏ (config/prompts/cleaner.md)

```markdown
–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ –æ–±—É—á–∞—é—â–∏—Ö –≤–∏–¥–µ–æ.

**–í–∏–¥–µ–æ:** {title}
**–°–ø–∏–∫–µ—Ä:** {speaker}

**–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:**

1. **–£–¥–∞–ª–∏ —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã:**
   - "–Ω—É", "–≤–æ—Ç", "–∫–∞–∫ –±—ã", "—Ç–∏–ø–∞", "–∑–Ω–∞—á–∏—Ç"
   - "—ç—ç—ç", "–º–º–º", "–∞–∞–∞" –∏ –ø–æ–¥–æ–±–Ω—ã–µ
   - –ò–∑–±—ã—Ç–æ—á–Ω—ã–µ "—Ç–æ –µ—Å—Ç—å", "—Ç–∞–∫ —Å–∫–∞–∑–∞—Ç—å"

2. **–£–¥–∞–ª–∏ –æ—Ç–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç —Ç–µ–º—ã:**
   - –õ–∏—á–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏, –Ω–µ –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —Ç–µ–º–µ
   - –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã ("–ø–æ–¥–æ–∂–¥–∏—Ç–µ, —Å–µ–π—á–∞—Å –Ω–∞—Å—Ç—Ä–æ—é")
   - –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –ø—Ä–æ—â–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª–∞)

3. **–ò—Å–ø—Ä–∞–≤—å –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏ —Ä–µ—á–∏:**
   - –û–±–æ—Ä–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ‚Äî –∑–∞–≤–µ—Ä—à–∏ –∏–ª–∏ —É–¥–∞–ª–∏
   - –ü–æ–≤—Ç–æ—Ä—ã —Å–ª–æ–≤ ‚Äî –æ—Å—Ç–∞–≤—å –æ–¥–∏–Ω —Ä–∞–∑
   - –°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ ("–Ω–µ—Ç, –Ω–µ —Ç–∞–∫, –∞ –≤–æ—Ç —Ç–∞–∫") ‚Äî –æ—Å—Ç–∞–≤—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç

4. **–°–û–•–†–ê–ù–ò:**
   - –í–µ—Å—å —Å–º—ã—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
   - –ü—Ä–∏–º–µ—Ä—ã –∏ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ —Ç–µ–º–µ
   - –°—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑–ª–æ–∂–µ–Ω–∏—è
   - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é

**–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏:**

{transcript}

**–û—Ç–≤–µ—Ç:**
–û—á–∏—â–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤):
```

### –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö

```python
@dataclass
class CleanedTranscript:
    """–û—á–∏—â–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç."""
    
    text: str                         # –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    original_length: int              # –î–ª–∏–Ω–∞ –¥–æ –æ—á–∏—Å—Ç–∫–∏ (—Å–∏–º–≤–æ–ª—ã)
    cleaned_length: int               # –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
    glossary_replacements: int        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–º–µ–Ω –ø–æ –≥–ª–æ—Å—Å–∞—Ä–∏—é
    
    @property
    def reduction_percent(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞."""
        return (1 - self.cleaned_length / self.original_length) * 100
```

---

## –≠—Ç–∞–ø 4: Chunk (Semantic Splitting)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–†–∞–∑–±–∏–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ –±–ª–æ–∫–∏ –¥–ª—è RAG.

### –ü—Ä–∏–Ω—Ü–∏–ø—ã chunking

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ó–Ω–∞—á–µ–Ω–∏–µ | –ü–æ—á–µ–º—É |
|----------|----------|--------|
| –†–∞–∑–º–µ—Ä chunk | 100-400 —Å–ª–æ–≤ | –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è embeddings |
| –°–º—ã—Å–ª–æ–≤–∞—è –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç—å | –û–¥–Ω–∞ —Ç–µ–º–∞/–º—ã—Å–ª—å | Chunk –ø–æ–Ω—è—Ç–µ–Ω –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ |
| Overlap | –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è | –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω |

### LLM Chunking (Ollama)

```python
async def chunk_transcript(
    cleaned_text: str,
    metadata: VideoMetadata,
    client: AsyncClient
) -> list[dict]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ –±–ª–æ–∫–∏ —á–µ—Ä–µ–∑ LLM.
    
    Returns:
        List of chunks with topic and text
    """
    
    prompt = load_prompt("config/prompts/chunker.md")
    prompt = prompt.format(
        title=metadata.title,
        transcript=cleaned_text
    )
    
    response = await client.chat(
        model="qwen2.5:14b",
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": 0.3},
        format="json"  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º JSON –æ—Ç–≤–µ—Ç
    )
    
    return json.loads(response["message"]["content"])["chunks"]
```

### –ü—Ä–æ–º–ø—Ç chunking (config/prompts/chunker.md)

```markdown
–†–∞–∑–±–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ –±–ª–æ–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.

**–í–∏–¥–µ–æ:** {title}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–ª–æ–∫–∞–º:**
1. –ö–∞–∂–¥—ã–π –±–ª–æ–∫ ‚Äî –æ–¥–Ω–∞ –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–∞—è —Ç–µ–º–∞ –∏–ª–∏ –º—ã—Å–ª—å
2. –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞: 100-400 —Å–ª–æ–≤
3. –ë–ª–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–µ–Ω –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥—Ä—É–≥–∏—Ö –±–ª–æ–∫–æ–≤
4. –°–æ—Ö—Ä–∞–Ω–∏ –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç, –Ω–∏—á–µ–≥–æ –Ω–µ —É–¥–∞–ª—è–π

**–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:**

{transcript}

**–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (JSON):**

```json
{
  "chunks": [
    {
      "index": 1,
      "topic": "–ö—Ä–∞—Ç–∫–∞—è —Ç–µ–º–∞ –±–ª–æ–∫–∞ (3-7 —Å–ª–æ–≤)",
      "text": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞..."
    },
    {
      "index": 2,
      "topic": "...",
      "text": "..."
    }
  ]
}
```

**–û—Ç–≤–µ—Ç:**
```

### –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö

```python
@dataclass
class TranscriptChunk:
    """–û–¥–∏–Ω —Å–º—ã—Å–ª–æ–≤–æ–π –±–ª–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞."""
    
    id: str                # {video_id}_{index:03d}
    index: int             # –ü–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä (1, 2, 3...)
    topic: str             # –ö—Ä–∞—Ç–∫–∞—è —Ç–µ–º–∞ –±–ª–æ–∫–∞
    text: str              # –¢–µ–∫—Å—Ç –±–ª–æ–∫–∞
    word_count: int        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–¥–ª—è –±—É–¥—É—â–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
    # start_time: str | None = None
    # end_time: str | None = None


@dataclass 
class TranscriptChunks:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç chunking."""
    
    video_id: str
    chunks: list[TranscriptChunk]
    total_chunks: int
    avg_chunk_size: int              # –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –≤ —Å–ª–æ–≤–∞—Ö
```

---

## –≠—Ç–∞–ø 5: Summarize (+ Classification)

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ –¥–ª—è File Search –≤ –ë–ó 2.0.

### LLM Summarization

```python
async def summarize_transcript(
    cleaned_text: str,
    metadata: VideoMetadata,
    client: AsyncClient
) -> dict:
    """
    –°–æ–∑–¥–∞—ë—Ç —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è –ë–ó 2.0.
    
    Returns:
        {
            "summary": "...",
            "key_points": [...],
            "recommendations": [...],
            "target_audience": "...",
            "classification": {
                "section": "...",
                "subsection": "...",
                "tags": [...]
            }
        }
    """
    
    prompt = load_prompt("config/prompts/summarizer.md")
    prompt = prompt.format(
        title=metadata.title,
        speaker=metadata.speaker,
        date=metadata.date.strftime("%d %B %Y"),
        stream=metadata.stream_full,
        transcript=cleaned_text
    )
    
    response = await client.chat(
        model="qwen2.5:14b",
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": 0.5},
        format="json"
    )
    
    return json.loads(response["message"]["content"])
```

### –ü—Ä–æ–º–ø—Ç —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (config/prompts/summarizer.md)

```markdown
–°–æ–∑–¥–∞–π —Å–∞–º–º–∞—Ä–∏ –æ–±—É—á–∞—é—â–µ–≥–æ –≤–∏–¥–µ–æ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–≤ Herbalife.

**–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:**
- –¢–µ–º–∞: {title}
- –°–ø–∏–∫–µ—Ä: {speaker}
- –î–∞—Ç–∞: {date}
- –ü–æ—Ç–æ–∫: {stream}

**–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:**

{transcript}

**–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ –≤ JSON:**

```json
{
  "summary": "2-3 –∞–±–∑–∞—Ü–∞: –æ —á—ë–º –≤–∏–¥–µ–æ –∏ –∫–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç",
  
  "key_points": [
    "–ö–ª—é—á–µ–≤–æ–π —Ç–µ–∑–∏—Å 1",
    "–ö–ª—é—á–µ–≤–æ–π —Ç–µ–∑–∏—Å 2",
    "–ö–ª—é—á–µ–≤–æ–π —Ç–µ–∑–∏—Å 3"
  ],
  
  "recommendations": [
    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 1",
    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 2",
    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 3"
  ],
  
  "target_audience": "–î–ª—è –∫–æ–≥–æ –ø–æ–ª–µ–∑–Ω–æ —ç—Ç–æ –≤–∏–¥–µ–æ",
  
  "classification": {
    "section": "–û–¥–∏–Ω –∏–∑: –û–±—É—á–µ–Ω–∏–µ | –ü—Ä–æ–¥—É–∫—Ç—ã | –ë–∏–∑–Ω–µ—Å | –ú–æ—Ç–∏–≤–∞—Ü–∏—è",
    "subsection": "–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤–Ω—É—Ç—Ä–∏ —Å–µ–∫—Ü–∏–∏",
    "tags": ["—Ç–µ–≥1", "—Ç–µ–≥2", "—Ç–µ–≥3", "—Ç–µ–≥4", "—Ç–µ–≥5"],
    "access_level": 1
  },
  
  "questions_answered": [
    "–ù–∞ –∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å –æ—Ç–≤–µ—á–∞–µ—Ç –≤–∏–¥–µ–æ 1?",
    "–ù–∞ –∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å –æ—Ç–≤–µ—á–∞–µ—Ç –≤–∏–¥–µ–æ 2?",
    "–ù–∞ –∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å –æ—Ç–≤–µ—á–∞–µ—Ç –≤–∏–¥–µ–æ 3?"
  ]
}
```

**–û—Ç–≤–µ—Ç:**
```

### –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö

```python
@dataclass
class VideoSummary:
    """–°–∞–º–º–∞—Ä–∏ –≤–∏–¥–µ–æ –¥–ª—è –ë–ó 2.0."""
    
    # –ö–æ–Ω—Ç–µ–Ω—Ç
    summary: str                      # –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    key_points: list[str]             # –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã
    recommendations: list[str]        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    target_audience: str              # –î–ª—è –∫–æ–≥–æ –ø–æ–ª–µ–∑–Ω–æ
    questions_answered: list[str]     # –í–æ–ø—Ä–æ—Å—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞–µ—Ç
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    section: str                      # –û–±—É—á–µ–Ω–∏–µ / –ü—Ä–æ–¥—É–∫—Ç—ã / –ë–∏–∑–Ω–µ—Å / –ú–æ—Ç–∏–≤–∞—Ü–∏—è
    subsection: str                   # –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è
    tags: list[str]                   # –¢–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
    access_level: int                 # –£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–∞ (1-4)
```

---

## –≠—Ç–∞–ø 6: Save Files

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤.

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞—Ä—Ö–∏–≤–∞

```
/archive/
‚îî‚îÄ‚îÄ {–≥–æ–¥}/
    ‚îî‚îÄ‚îÄ {–º–µ—Å—è—Ü}/
        ‚îî‚îÄ‚îÄ {—Ç–∏–ø}.{–ø–æ—Ç–æ–∫}/
            ‚îî‚îÄ‚îÄ {—Ç–µ–º–∞} ({—Å–ø–∏–∫–µ—Ä})/
                ‚îú‚îÄ‚îÄ {original_filename}.mp4      # –í–∏–¥–µ–æ
                ‚îú‚îÄ‚îÄ transcript_chunks.json       # –î–ª—è RAG
                ‚îú‚îÄ‚îÄ summary.md                   # –î–ª—è File Search
                ‚îî‚îÄ‚îÄ transcript_raw.txt           # Backup –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è transcript_chunks.json

```python
def save_transcript_chunks(
    video_id: str,
    metadata: VideoMetadata,
    raw_transcript: RawTranscript,
    chunks: TranscriptChunks,
    archive_path: Path
) -> Path:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç chunks –≤ JSON –¥–ª—è RAG-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    """
    
    data = {
        "video_id": video_id,
        "metadata": {
            "title": metadata.title,
            "speaker": metadata.speaker,
            "date": metadata.date.isoformat(),
            "stream": metadata.stream,
            "stream_name": metadata.stream_full,
            "duration_seconds": raw_transcript.duration_seconds,
            "language": raw_transcript.language,
            "whisper_model": raw_transcript.whisper_model,
            "processed_at": datetime.now().isoformat(),
        },
        "chunks": [
            {
                "id": chunk.id,
                "index": chunk.index,
                "topic": chunk.topic,
                "text": chunk.text,
                "word_count": chunk.word_count,
            }
            for chunk in chunks.chunks
        ],
        "statistics": {
            "total_chunks": chunks.total_chunks,
            "avg_chunk_size": chunks.avg_chunk_size,
        }
    }
    
    output_path = archive_path / "transcript_chunks.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return output_path
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary.md

```python
def save_summary_md(
    video_id: str,
    metadata: VideoMetadata,
    raw_transcript: RawTranscript,
    summary: VideoSummary,
    archive_path: Path
) -> Path:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç summary.md —Å YAML frontmatter –¥–ª—è –ë–ó 2.0.
    """
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    duration = format_duration(raw_transcript.duration_seconds)
    
    content = f'''---
# === –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è ===
video_id: "{video_id}"
title: "{metadata.title}"
type: "video_summary"

# === –ò—Å—Ç–æ—á–Ω–∏–∫ ===
speaker: "{metadata.speaker}"
date: "{metadata.date.isoformat()}"
stream: "{metadata.stream}"
stream_name: "{metadata.stream_full}"
duration: "{duration}"

# === –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –ë–ó 2.0 ===
section: "{summary.section}"
subsection: "{summary.subsection}"
access_level: {summary.access_level}
tags:
{format_yaml_list(summary.tags)}

# === –°—Å—ã–ª–∫–∏ ===
transcript_file: "transcript_chunks.json"

# === –°–ª—É–∂–µ–±–Ω–æ–µ ===
created: "{datetime.now().isoformat()}"
llm_model: "qwen2.5:14b"
---

# {metadata.title}

**–°–ø–∏–∫–µ—Ä:** {metadata.speaker}  
**–î–∞—Ç–∞:** {metadata.date.strftime("%d %B %Y")}  
**–ü–æ—Ç–æ–∫:** {metadata.stream_full}

---

## –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

{summary.summary}

## –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã

{format_bullet_list(summary.key_points)}

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

{format_numbered_list(summary.recommendations)}

## –î–ª—è –∫–æ–≥–æ –ø–æ–ª–µ–∑–Ω–æ

{summary.target_audience}

## –í–æ–ø—Ä–æ—Å—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞–µ—Ç –≤–∏–¥–µ–æ

{format_bullet_list(summary.questions_answered)}

---

üìù **–ü–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:** –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
'''
    
    output_path = archive_path / "summary.md"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(content)
    
    return output_path
```

### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ raw —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ (backup)

```python
def save_raw_transcript(
    raw_transcript: RawTranscript,
    archive_path: Path
) -> Path:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —Ç–∞–π–º-–∫–æ–¥–∞–º–∏.
    Backup –Ω–∞ —Å–ª—É—á–∞–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏.
    """
    
    output_path = archive_path / "transcript_raw.txt"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(raw_transcript.text_with_timestamps)
    
    return output_path
```

---

## –ü–æ–ª–Ω—ã–π Pipeline Flow

```python
async def process_video(video_path: Path) -> ProcessingResult:
    """
    –ü–æ–ª–Ω—ã–π pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ.
    """
    
    # 1. Parse filename
    metadata = parse_filename(video_path.name)
    video_id = generate_video_id(metadata)
    
    # 2. Transcribe
    raw_transcript = await transcribe(video_path, WHISPER_CONFIG)
    
    # 3. Clean
    glossary = load_glossary()
    text_with_glossary = apply_glossary(raw_transcript.full_text, glossary)
    cleaned_text = await llm_clean_transcript(text_with_glossary, metadata)
    
    # 4. Chunk
    chunks = await chunk_transcript(cleaned_text, metadata)
    
    # 5. Summarize
    summary = await summarize_transcript(cleaned_text, metadata)
    
    # 6. Save
    archive_path = create_archive_path(metadata)
    
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤–∏–¥–µ–æ
    shutil.move(video_path, archive_path / video_path.name)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_transcript_chunks(video_id, metadata, raw_transcript, chunks, archive_path)
    save_summary_md(video_id, metadata, raw_transcript, summary, archive_path)
    save_raw_transcript(raw_transcript, archive_path)
    
    return ProcessingResult(
        video_id=video_id,
        archive_path=archive_path,
        chunks_count=len(chunks),
        duration=raw_transcript.duration_seconds,
    )
```

---

## Error Handling

### –¢–∏–ø—ã –æ—à–∏–±–æ–∫

| –≠—Ç–∞–ø | –û—à–∏–±–∫–∞ | –î–µ–π—Å—Ç–≤–∏–µ |
|------|--------|----------|
| 1. Parse | –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏ | –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å, —É–≤–µ–¥–æ–º–∏—Ç—å |
| 2. Whisper | OOM (–Ω–µ—Ö–≤–∞—Ç–∫–∞ VRAM) | Retry —Å –º–µ–Ω—å—à–µ–π –º–æ–¥–µ–ª—å—é |
| 2. Whisper | Corrupted video | –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å, —É–≤–µ–¥–æ–º–∏—Ç—å |
| 3-5. LLM | Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω | Retry —Å backoff |
| 3-5. LLM | Invalid JSON response | Retry (–¥–æ 3 —Ä–∞–∑) |
| 6. Save | Disk full | –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å pipeline |

### Retry –ª–æ–≥–∏–∫–∞

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=60)
)
async def call_ollama_with_retry(prompt: str, **kwargs):
    """–í—ã–∑–æ–≤ Ollama —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º retry."""
    return await ollama_client.chat(...)
```

---

## –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [architecture.md](architecture.md) ‚Äî —Å—Ö–µ–º–∞ —Å–∏—Å—Ç–µ–º—ã, –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- [data-formats.md](data-formats.md) ‚Äî –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤
- [llm-prompts.md](llm-prompts.md) ‚Äî –≤—Å–µ –ø—Ä–æ–º–ø—Ç—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
