---
type: справка
date: 2025-01-20
tags:
  - бюджет
  - api
  - workflow
---

# Расчёт стоимости обработки транскриптов через API

## Исходные данные

**Объём работы:** ~100 тем в год (5 событий × 20 тем)

**Результат на 1 тему:**
- Лонгрид (~2,500 слов)
- Конспект (~1,200 слов)

---

## Токены на 1 тему

| Компонент | Input | Output |
|-----------|------:|-------:|
| Системный промпт + инструкции | 25,000 | — |
| Транскрипт (~40 мин) | 12,000 | — |
| Контекст беседы | 10,000 | — |
| Лонгрид | — | 5,500 |
| Конспект | — | 2,800 |
| Служебное | — | 800 |
| **Итого** | **47,000** | **9,100** |

---

## Цены API (январь 2025)

### Anthropic Claude

| Модель | Input (за 1M) | Output (за 1M) |
|--------|-------------:|---------------:|
| Opus 4.5 | $5 | $25 |
| Sonnet 4.5 | $3 | $15 |
| Haiku 4.5 | $1 | $5 |

### OpenAI GPT

| Модель | Input (за 1M) | Output (за 1M) |
|--------|-------------:|---------------:|
| GPT-5.2 | $1.75 | $14 |
| GPT-5.2 Pro | $21 | $168 |
| GPT-4.1 | $2 | $8 |
| GPT-4o | $2.50 | $10 |

**Batch API:** скидка 50% у обоих провайдеров

---

## Стоимость по моделям

### 1 тема

| Модель | Input | Output | Итого | Batch API |
|--------|------:|-------:|------:|----------:|
| Claude Opus 4.5 | $0.24 | $0.23 | **$0.47** | $0.24 |
| Claude Sonnet 4.5 | $0.14 | $0.14 | **$0.28** | $0.14 |
| Claude Haiku 4.5 | $0.05 | $0.05 | **$0.09** | $0.05 |
| GPT-5.2 | $0.08 | $0.13 | **$0.21** | $0.11 |
| GPT-4.1 | $0.09 | $0.07 | **$0.17** | $0.09 |

### 100 тем (год)

| Модель | Стандартный API | Batch API |
|--------|---------------:|-----------:|
| Claude Opus 4.5 | $47 | $24 |
| Claude Sonnet 4.5 | $28 | $14 |
| Claude Haiku 4.5 | $9 | $5 |
| GPT-5.2 | $21 | $11 |
| GPT-4.1 | $17 | $9 |

---

## Сравнение качества для задачи

### Специфика задачи

Обработка транскриптов обучающих тем требует:
- Сохранение авторского голоса и стиля спикера
- Естественность и «живость» текста
- Работа с русским языком
- Следование сложным стилистическим инструкциям
- Баланс между редактированием и сохранением оригинала

### Сильные стороны моделей

| Критерий | Claude | GPT-5.2 |
|----------|--------|---------|
| Фокус разработки | Творческие и текстовые задачи | Код, math, agentic tasks |
| Следование стилю | ⭐⭐⭐ | ⭐⭐ |
| «Живость» текста | ⭐⭐⭐ | ⭐⭐ (?) |
| Русский язык | ⭐⭐⭐ | ⭐⭐ |
| Структурирование | Гибко | Более шаблонно |
| Цена | Выше | Ниже на 25% |

### Подозрение насчёт «живости»

GPT-5.2 позиционируется OpenAI как модель для **coding и agentic tasks**. Бенчмарки фокусируются на коде, математике, tool calling. Это вызывает обоснованные сомнения:

1. **Оптимизация под другие задачи** — модель натренирована давать структурированные, точные ответы, а не «человечные» тексты
2. **Исторический паттерн** — GPT традиционно пишет более «сухо» и шаблонно, чем Claude
3. **Субъективные отзывы** — пользователи отмечают, что Claude лучше справляется с творческим редактированием

**Риск:** лонгриды могут получиться технически правильными, но потерять авторский голос спикера — ту самую «живость», которая делает документы ценными.

---

## Рекомендация

### Основной выбор: Claude Sonnet 4.5

**Почему не GPT-5.2 (несмотря на цену -25%):**
- Экономия $7/год не оправдывает риск потери качества
- Задача требует именно тех навыков, в которых Claude сильнее
- «Живость» документов — ключевая ценность для RAG и обучения команды

**Почему не Opus:**
- Избыточен для задач редактирования
- Экономия 40% при сопоставимом качестве

**Почему не Haiku:**
- Риск упрощения структуры и потери нюансов

### Когда рассмотреть GPT-5.2

- Если после тестирования качество устроит
- Для технических тем без выраженного авторского стиля
- При значительном увеличении объёмов (500+ тем/год)

### Как проверить

Прогнать 2-3 транскрипта через GPT-5.2 с теми же инструкциями. Оценить:
- [ ] Сохранился ли авторский голос?
- [ ] Насколько естественно читается?
- [ ] Не стал ли текст «сухим» или шаблонным?
- [ ] Сохранены ли характерные обороты спикера?

---

## Итоговый расчёт

### Рекомендуемый стек (Claude)

| Задача | Модель | Тем/год | Стоимость |
|--------|--------|--------:|----------:|
| Лонгрид + конспект | Sonnet 4.5 | 100 | $28 |
| Буфер на доработки (+30%) | Sonnet 4.5 | — | $8 |
| Сложные темы (10%) | Opus 4.5 | 10 | $5 |
| **Итого** | — | — | **~$41** |

С Batch API: **~$21**

### Альтернатива (GPT-5.2, если тест пройдёт)

| Задача | Модель | Тем/год | Стоимость |
|--------|--------|--------:|----------:|
| Лонгрид + конспект | GPT-5.2 | 100 | $21 |
| Буфер (+30%) | GPT-5.2 | — | $6 |
| **Итого** | — | — | **~$27** |

С Batch API: **~$14**

---

## Сравнение вариантов (год)

| Вариант | Стоимость | Качество | Примечание |
|---------|----------:|:--------:|------------|
| Claude Pro подписка | $240 | ⭐⭐⭐ | Универсально, лимиты |
| Claude Sonnet API | $28-41 | ⭐⭐⭐ | **Рекомендуется** |
| GPT-5.2 API | $21-27 | ⭐⭐ (?) | Требует тестирования |
| Claude Batch | $14-21 | ⭐⭐⭐ | Если не критична скорость |

---

## Формула для пересчёта

```
Стоимость = (Input × Rate_in + Output × Rate_out) / 1,000,000

Sonnet 4.5: (47,000 × $3 + 9,100 × $15) / 1M = $0.28
GPT-5.2:    (47,000 × $1.75 + 9,100 × $14) / 1M = $0.21
```

---

## Вывод

**Платим за качество, а не за токены.**

Разница $7-14/год между Claude и GPT — это цена уверенности в том, что документы сохранят авторский голос и останутся «живыми». Для базы знаний, которая будет использоваться командой годами, это оправданная инвестиция.

> Актуальные цены: [anthropic.com/pricing](https://www.anthropic.com/pricing) | [openai.com/api/pricing](https://openai.com/api/pricing)
