# Обработка длинных транскриптов для RAG

## Контекст документа

Этот документ описывает подход к обработке длинных видеотранскриптов для загрузки в систему RAG (Retrieval-Augmented Generation) в проекте "База Знаний 2.0".

**Цели обработки:**
- **Саммаризация** — для поиска видео по содержимому
- **Чанкирование** — для ответов на вопросы из RAG

**Ограничения:**
- Контекст LLM: 32K токенов (qwen2.5:14b)
- Транскрипты: до 220 KB (2 часа видео, ~55K слов)

---

## Часть 1: Проблема

### 1.1. Суть проблемы

Транскрипт 2-часового видео (~220 KB, ~55,000 слов) не помещается в контекст LLM (32K токенов ≈ 24,000 слов). Необходимо разбивать на части.

**Наивный подход — разбиение "вслепую":**

```
Транскрипт 220 KB
       │
       ▼
┌──────────┬──────────┬──────────┬──────────┐
│ Часть 1  │ Часть 2  │ Часть 3  │ Часть N  │
│ 0-8000   │ 8000-    │ 16000-   │   ...    │
│ символов │ 16000    │ 24000    │          │
└──────────┴──────────┴──────────┴──────────┘
     ↑           ↑
  РАЗРЫВ      РАЗРЫВ
   ТЕМЫ        ТЕМЫ
```

**Проблемы:**
1. Тема может начаться в одной части и закончиться в другой
2. LLM не видит глобальную структуру видео
3. Чанки на границах частей теряют контекст
4. Саммари каждой части не связаны между собой

### 1.2. Пример проблемы границ

```
РЕАЛЬНЫЙ ТРАНСКРИПТ:

"...витамин D важен для костей. Теперь поговорим о белке.
Белок необходим для построения мышц. Рекомендуется употреблять
1.5 грамма на килограмм веса. Особенно важно получать белок
утром, потому что [ГРАНИЦА 8000 СИМВОЛОВ] метаболизм в это
время активнее. Также белок помогает контролировать аппетит.
Переходим к углеводам..."

ЧАСТЬ 1 видит: "...начали про белок, 1.5 грамма..."
ЧАСТЬ 2 видит: "...метаболизм активнее, белок для аппетита, углеводы..."

→ Ни одна часть не видит тему "белок" целиком
→ LLM в части 2 не знает, что "метаболизм" относится к теме белка
```

### 1.3. Особенности видеотранскриптов

В отличие от документов, видеотранскрипты — **"шумный" источник**:

| Аспект | Документы | Видеотранскрипты |
|--------|-----------|------------------|
| Точность | Выверены, отредактированы | Спикер ошибается, оговаривается |
| Структура | Чёткая (заголовки, разделы) | Неявная (поток речи) |
| Повторы | Минимальны | Спикер повторяется |
| Терминология | Точная | Может быть неточной |

**Вывод:** Нет смысла добиваться идеальной обработки "шумных" данных. Достаточно "хорошей" обработки.

---

## Часть 2: Сравнение решений

### 2.1. Обзор подходов

| Подход | Описание | Сложность | Время (2ч видео) |
|--------|----------|-----------|------------------|
| **Наивный** | Разбить → обработать независимо | Низкая | ~5 мин |
| **Overlap** | Части перекрываются на 15-20% | Низкая | ~6 мин |
| **Map-Reduce** | MAP: извлечь → REDUCE: объединить | Средняя | ~5 мин |
| **Map-Reduce + Overlap** | Overlap + MAP + REDUCE | Средняя | ~6 мин |
| **Refine** | Последовательно с накоплением | Высокая | ~9 мин |

### 2.2. Подход: Overlap (перекрытие)

Каждая часть включает конец предыдущей:

```
БЕЗ OVERLAP:
├─────Часть 1─────┤├─────Часть 2─────┤├─────Часть 3─────┤
                  ↑                  ↑
               разрыв             разрыв

С OVERLAP (1500 символов):
├─────────Часть 1─────────┤
                 ├────────overlap────────┤
                          ├─────────Часть 2─────────┤
                                   ├────────overlap────────┤
                                            ├─────────Часть 3─────────┤
```

**Плюсы:**
- Простая реализация
- Решает ~80% проблем с границами тем
- Минимальные изменения в существующем коде

**Минусы:**
- +15-20% объёма обработки
- Не решает проблему глобального контекста

### 2.3. Подход: Map-Reduce

```
       ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
       │Part1│ │Part2│ │Part3│ │Part4│
       └──┬──┘ └──┬──┘ └──┬──┘ └──┬──┘
          │      │       │       │
  MAP:    ▼      ▼       ▼       ▼        (параллельно)
       ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
       │Out 1│ │Out 2│ │Out 3│ │Out 4│    Компактные outline
       └──┬──┘ └──┬──┘ └──┬──┘ └──┬──┘
          │      │       │       │
          └──────┴───┬───┴───────┘
                     │
 REDUCE:             ▼
               ┌───────────┐
               │  Единый   │              Объединение + дедупликация
               │  Outline  │
               └───────────┘
```

**Плюсы:**
- Параллельная обработка (быстро)
- Единый Outline даёт глобальный контекст
- Outline помещается в контекст (~1500-2000 токенов)

**Минусы:**
- Дополнительный этап обработки
- Outline плоский (без иерархии тем)

### 2.4. Подход: Map-Reduce + Overlap (рекомендуемый)

Комбинация двух подходов:

```
┌─────────────────────────────────────────────────────────────────┐
│  ЭТАП 1: SPLIT WITH OVERLAP                                     │
│                                                                 │
│  Транскрипт → Части с перекрытием 1500 символов                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  ЭТАП 2: MAP (параллельно)                                      │
│                                                                 │
│  Каждая часть → LLM → {topics, key_points, summary}             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  ЭТАП 3: REDUCE                                                 │
│                                                                 │
│  Все outline → Дедупликация → Единый Outline                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                              │
              ┌───────────────┴───────────────┐
              ▼                               ▼
┌──────────────────────────┐    ┌──────────────────────────┐
│  CHUNKING                │    │  SUMMARIZATION           │
│                          │    │                          │
│  Часть + Outline → LLM   │    │  Outline + Meta → LLM    │
│  → Семантические чанки   │    │  → VideoSummary          │
│                          │    │                          │
│  (параллельно)           │    │  (один вызов)            │
└──────────────────────────┘    └──────────────────────────┘
```

**Почему этот подход:**
- Overlap решает проблему границ тем
- Outline даёт глобальный контекст для chunking и summarization
- Параллельная обработка сохраняет скорость
- Достаточная точность для "шумных" видеоданных

### 2.5. Подход: Refine (отклонён)

Последовательная обработка с накоплением контекста:

```
Часть 1 → LLM → Outline v1
                    │
Часть 2 + Outline v1 → LLM → Outline v2
                              │
Часть 3 + Outline v2 → LLM → Outline v3
                              ...
```

**Плюсы:**
- Точная иерархия тем (подтемы правильно вложены)
- Максимальное понимание структуры

**Минусы:**
- Последовательно (нельзя параллелить)
- +4 минуты на 2-часовом видео
- Избыточно для задач поиска видео и RAG

**Почему отклонён:**
- Иерархия тем не критична для поиска видео
- Иерархия не критична для RAG-ответов
- Дополнительное время не оправдано для "шумных" данных

---

## Часть 3: Концепция реализации

### 3.1. Общая схема

```
ВХОД: Очищенный транскрипт (CleanedTranscript)
      + Метаданные видео (VideoMetadata)

                    │
                    ▼
┌─────────────────────────────────────────────────────────────────┐
│  TextSplitter.split_with_overlap()                              │
│                                                                 │
│  - Размер части: ~8000 символов                                 │
│  - Overlap: 1500 символов                                       │
│  - Граница по предложениям (не резать слова)                    │
│                                                                 │
│  ВЫХОД: list[TextPart]                                          │
└─────────────────────────────────────────────────────────────────┘
                    │
                    ▼
┌─────────────────────────────────────────────────────────────────┐
│  OutlineExtractor.extract_parallel()                            │
│                                                                 │
│  Для каждой части (параллельно):                                │
│  - LLM извлекает: topics, key_points, summary                   │
│                                                                 │
│  ВЫХОД: list[PartOutline]                                       │
└─────────────────────────────────────────────────────────────────┘
                    │
                    ▼
┌─────────────────────────────────────────────────────────────────┐
│  OutlineExtractor.reduce()                                      │
│                                                                 │
│  - Объединить все PartOutline                                   │
│  - Дедупликация похожих тем (>60% совпадение слов)              │
│  - Сформировать единый TranscriptOutline                        │
│                                                                 │
│  ВЫХОД: TranscriptOutline (~1500-2000 токенов)                  │
└─────────────────────────────────────────────────────────────────┘
                    │
        ┌───────────┴───────────┐
        ▼                       ▼
┌───────────────┐       ┌───────────────┐
│  Chunker      │       │  Summarizer   │
│               │       │               │
│ Часть текста  │       │ Outline       │
│ + Outline     │       │ + Метаданные  │
│ + Prev chunks │       │               │
│      ↓        │       │      ↓        │
│    LLM        │       │    LLM        │
│      ↓        │       │      ↓        │
│   Chunks      │       │ VideoSummary  │
└───────────────┘       └───────────────┘

ВЫХОД: list[Chunk], VideoSummary
```

### 3.2. Модели данных

```python
class TextPart(BaseModel):
    """Часть транскрипта с информацией о позиции."""
    index: int                    # Порядковый номер части
    text: str                     # Текст части
    start_char: int               # Начальная позиция в оригинале
    end_char: int                 # Конечная позиция
    has_overlap_before: bool      # Есть ли overlap с предыдущей

class PartOutline(BaseModel):
    """Outline одной части транскрипта."""
    part_index: int
    topics: list[str]             # 2-4 темы
    key_points: list[str]         # 3-5 ключевых тезисов
    summary: str                  # 1-2 предложения

class TranscriptOutline(BaseModel):
    """Объединённый outline всего транскрипта."""
    parts: list[PartOutline]
    all_topics: list[str]         # Дедуплицированный список тем
    total_parts: int
    
    def to_context(self) -> str:
        """Форматирование для вставки в промпт LLM."""
        ...
```

### 3.3. Параметры разбиения

| Параметр | Значение | Обоснование |
|----------|----------|-------------|
| PART_SIZE | 8000 символов | ~3000 токенов, оставляет место для промпта |
| OVERLAP_SIZE | 1500 символов | ~20%, достаточно для контекста границы |
| MIN_PART_SIZE | 2000 символов | Не создавать слишком мелкие части |

### 3.4. Оценка времени

**Для 2-часового видео (220 KB, ~34 части):**

| Этап | Вызовов LLM | Время |
|------|-------------|-------|
| Split | 0 | ~1 сек |
| MAP (outline) | 34 (параллельно) | ~1.5 мин |
| REDUCE | 0 (локально) | ~1 сек |
| Chunking | 34 (параллельно) | ~2 мин |
| Summarization | 1 | ~30 сек |
| **ИТОГО** | ~69 | **~4-5 мин** |

### 3.5. Промпты

**MAP: Извлечение outline части**

```markdown
Проанализируй часть транскрипта видео и извлеки:

1. **Темы** (2-4): основные темы этой части
2. **Ключевые тезисы** (3-5): конкретные факты и рекомендации
3. **Краткое содержание** (1-2 предложения)

Формат JSON:
{
  "topics": ["тема1", "тема2"],
  "key_points": ["тезис1", "тезис2"],
  "summary": "О чём эта часть..."
}

ТЕКСТ:
{part_text}
```

**Chunking: С контекстом outline**

```markdown
Разбей текст на смысловые блоки для поиска информации.

КОНТЕКСТ ВСЕГО ВИДЕО:
{outline.to_context()}

ТЕКУЩАЯ ЧАСТЬ ({part_index + 1} из {total_parts}):
{part_text}

ПРЕДЫДУЩИЕ БЛОКИ (для связности):
{previous_chunks_summary}

Требования:
- Каждый блок: 100-400 слов, одна тема
- Блок должен быть понятен без контекста
- Учитывай общую структуру видео

Формат: JSON массив с полями topic, text
```

**Summarization: На основе outline**

```markdown
Создай структурированное описание видео для поиска.

МЕТАДАННЫЕ:
- Название: {title}
- Спикер: {speaker}
- Дата: {date}

СТРУКТУРА ВИДЕО:
{outline.to_context()}

Создай JSON:
{
  "summary": "2-3 абзаца о содержании",
  "key_points": ["тезис1", "тезис2", ...],
  "recommendations": ["рекомендация1", ...],
  "target_audience": "для кого полезно",
  "questions_answered": ["вопрос1", ...],
  "classification": {
    "section": "Обучение|Продукты|Бизнес|Мотивация",
    "subsection": "подкатегория",
    "tags": ["тег1", "тег2"],
    "access_level": 1
  }
}
```

---

## Часть 4: Входные данные для RAG-систем

### 4.1. Классический RAG (векторный поиск)

**Принцип работы:**
```
Чанки → Embeddings → Векторная БД → Семантический поиск
```

**Требования к данным:**

| Требование | Описание |
|------------|----------|
| Самодостаточность | Чанк понятен без контекста |
| Размер | 100-500 слов (оптимум для embeddings) |
| Метаданные | source_id, topic, speaker, date |
| Качество текста | Важно для качества embeddings |

**Формат чанка для RAG:**

```json
{
  "id": "2025-12-22_ПШ-SV_тестовая-запись_001",
  "text": "Текст чанка...",
  "metadata": {
    "source_type": "video_transcript",
    "video_id": "2025-12-22_ПШ-SV_тестовая-запись",
    "title": "Тестовая запись",
    "speaker": "Иван Петров",
    "date": "2025-12-22",
    "topic": "Приветствие и вступление",
    "chunk_index": 1,
    "total_chunks": 6
  }
}
```

**Особенности:**
- Каждый чанк индексируется независимо
- Поиск по семантической близости вопроса к чанку
- Метаданные для фильтрации (по спикеру, дате, теме)

### 4.2. LightRAG (граф знаний)

**Принцип работы:**
```
Текст → Извлечение сущностей и связей → Граф знаний
                                              │
Запрос → Поиск по графу + векторный поиск → Ответ
```

**Отличия от классического RAG:**

| Аспект | Классический RAG | LightRAG |
|--------|------------------|----------|
| Структура | Плоский список чанков | Граф сущностей и связей |
| Поиск | Только семантический | Граф + семантический |
| Связи между фактами | Не учитываются | Явно моделируются |
| Multi-hop вопросы | Слабо | Хорошо |

**Пример преимущества LightRAG:**

```
Вопрос: "Какие рекомендации по белку давал Иван Петров?"

Классический RAG:
- Ищет чанки похожие на "белок" и "Иван Петров"
- Может найти чанки где упоминается белок, но не Петров
- Или где Петров говорит о другом

LightRAG:
- Граф: [Иван Петров] --говорил_о--> [Белок]
- Граф: [Белок] --рекомендация--> [1.5г на кг веса]
- Граф: [Белок] --важно--> [утром]
- Точный обход графа от Петров → Белок → рекомендации
```

**Требования к данным для LightRAG:**

| Требование | Описание |
|------------|----------|
| Чистый текст | LightRAG сам извлекает сущности |
| Контекст | Лучше подавать связный текст, не мелкие чанки |
| Метаданные | source_id для трассировки |

**Формат данных для LightRAG:**

```json
{
  "id": "2025-12-22_ПШ-SV_тестовая-запись",
  "text": "Полный очищенный транскрипт или крупные секции...",
  "metadata": {
    "source_type": "video_transcript",
    "title": "Тестовая запись",
    "speaker": "Иван Петров",
    "date": "2025-12-22",
    "reliability": "medium"
  }
}
```

**Важно:** LightRAG лучше работает с более крупными текстовыми блоками, так как ему нужен контекст для извлечения связей между сущностями.

### 4.3. Сравнение форматов

**Для классического RAG (текущая реализация):**

```json
{
  "video_id": "...",
  "metadata": { ... },
  "chunks": [
    {
      "id": "..._001",
      "topic": "Тема чанка",
      "text": "Текст 100-400 слов",
      "word_count": 150
    }
  ]
}
```

**Для LightRAG (будущая интеграция):**

```json
{
  "video_id": "...",
  "metadata": { ... },
  "sections": [
    {
      "id": "..._section_01",
      "topic": "Макронутриенты",
      "text": "Объединённый текст секции 1000-3000 слов",
      "subtopics": ["Белки", "Жиры", "Углеводы"]
    }
  ]
}
```

### 4.4. Универсальный формат (рекомендация)

Для поддержки обоих подходов — генерировать оба формата:

```json
{
  "video_id": "2025-12-22_ПШ-SV_тестовая-запись",
  "metadata": {
    "title": "Тестовая запись",
    "speaker": "Иван Петров",
    "date": "2025-12-22",
    "source_type": "video_transcript",
    "reliability": "medium",
    "duration_seconds": 3600
  },
  
  "for_vector_rag": {
    "chunks": [
      {
        "id": "..._001",
        "topic": "...",
        "text": "100-400 слов",
        "word_count": 150
      }
    ]
  },
  
  "for_graph_rag": {
    "sections": [
      {
        "id": "..._section_01",
        "topic": "...",
        "text": "1000-3000 слов",
        "subtopics": ["...", "..."]
      }
    ],
    "full_text": "Полный очищенный транскрипт"
  },
  
  "summary": {
    "text": "Краткое описание для поиска видео",
    "key_points": ["...", "..."],
    "tags": ["...", "..."]
  }
}
```

### 4.5. Поле reliability

Для разделения источников по надёжности:

| Значение | Источник | Описание |
|----------|----------|----------|
| `high` | Документы | Выверенные, отредактированные |
| `medium` | Видео обучения | Структурированные, но спикер может ошибаться |
| `low` | Видео встреч | Свободное общение, много "шума" |

**Использование:**
- При ответе можно приоритизировать источники с высокой надёжностью
- Можно предупреждать пользователя: "На основе видеозаписи (проверьте в документации)"

---

## Часть 5: Альтернатива — модели с большим контекстом

### 5.1. Теоретическая возможность

Qwen2.5 официально поддерживает контекст до 128K токенов. Теоретически это позволило бы обработать 2-часовой транскрипт (~55K слов ≈ 70K токенов) за один вызов LLM без разбиения на части.

### 5.2. Почему не подходит для домашнего сервера

**Требования к VRAM:**

| Модель | Контекст | VRAM нужно | RTX 5070 Ti (16 GB) |
|--------|----------|------------|---------------------|
| qwen2.5:14b | 32K | ~9-11 GB | ✅ Работает |
| qwen2.5:14b | 128K | ~30 GB | ❌ Не влезет |
| qwen2.5:7b | 128K | ~15-20 GB | ⚠️ На грани, качество ↓ |
| mistral-nemo:12b | 128K | ~20-23 GB | ❌ Не влезет |

**Причина:** При увеличении контекста растёт KV-cache. Для 14B модели при 128K контексте только KV-cache занимает ~20 GB, плюс веса модели ~9 GB.

### 5.3. Качество при большом контексте

Даже если бы VRAM хватило, большой контекст — не "серебряная пуля":

| Проблема | Описание |
|----------|----------|
| **Lost in the Middle** | LLM хуже работает с информацией в середине длинного контекста |
| **Скорость** | Один вызов с 128K медленнее чем несколько параллельных с 8K |
| **Цена ошибки** | Если LLM ошибётся — потеряна вся обработка |

### 5.4. Вывод

**Map-Reduce + Overlap остаётся оптимальным решением:**

- ✅ Работает на текущем железе (16 GB VRAM)
- ✅ Параллельная обработка — быстрее
- ✅ Outline даёт глобальный контекст
- ✅ Нет проблемы "lost in the middle"
- ✅ Отказоустойчивость — ошибка в одной части не теряет всё

**Когда пересмотреть:**
- GPU с 24-48 GB VRAM (RTX 4090, RTX 5090, A6000)
- Или облачные модели (GPT-4o, Claude) для критичных задач

---

## Часть 6: Ограничения и компромиссы

### 6.1. Принятые ограничения

| Ограничение | Почему приемлемо |
|-------------|------------------|
| Плоская структура тем | Не критично для поиска и RAG |
| ~20% overlap overhead | Приемлемая цена за качество границ |
| Возможные дубли тем | Дедупликация решает большинство случаев |
| Нет иерархии подтем | Избыточно для "шумных" видеоданных |

### 6.2. Когда пересмотреть подход

- Если качество RAG-ответов неприемлемо → попробовать Refine
- Если LightRAG требует иерархию → добавить этап построения иерархии
- Если видео > 4 часов → может потребоваться дополнительная оптимизация

### 6.3. Метрики качества

**Для саммаризации:**
- Видео находится по релевантным ключевым словам
- Классификация (section) корректна в >90% случаев

**Для чанков:**
- Чанки самодостаточны (понятны без контекста)
- Размер в пределах 100-400 слов
- RAG находит релевантные чанки по вопросам

---

## Приложение: Глоссарий

| Термин | Описание |
|--------|----------|
| **Overlap** | Перекрытие частей — конец одной части повторяется в начале следующей |
| **MAP** | Этап параллельной обработки частей |
| **REDUCE** | Этап объединения результатов обработки |
| **Outline** | Компактное описание структуры транскрипта (темы, тезисы) |
| **Чанк** | Смысловой блок текста для RAG (100-400 слов) |
| **RAG** | Retrieval-Augmented Generation — поиск + генерация ответа |
| **LightRAG** | RAG на основе графа знаний |
| **Embeddings** | Векторное представление текста для семантического поиска |
