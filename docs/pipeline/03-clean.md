# Этап 3: Clean (Очистка транскрипта)

[< Назад: Transcribe](02-transcribe.md) | [Обзор Pipeline](README.md) | [Далее: Chunk >](04-chunk.md)

---

## Назначение

Очистка сырого транскрипта от речевого мусора и нормализация терминологии.

## Проблемы сырого транскрипта

| Проблема | Пример | Решение |
|----------|--------|---------|
| Слова-паразиты | "ну", "вот", "как бы", "эээ" | LLM удаляет |
| Отвлечения | "видно экран?", "вы меня слышите?" | LLM удаляет |
| Ошибки Whisper | "Формула один" | Глоссарий исправляет |
| Термины Herbalife | "гербалайф", "СВ", "гет тим" | Глоссарий нормализует |

## Архитектура очистки

```
RawTranscript (~70KB контента для 55-мин видео)
       │
       ▼
┌─────────────────┐
│ 1. GLOSSARY     │  Быстрая замена терминов (Python regex)
│    (мгновенно)  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ 2. CHUNKING     │  Разбиение на части ~3KB
│    (~24 чанка)  │  (для стабильной обработки)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ 3. LLM CLEAN    │  Chat API с system/user roles
│    (по частям)  │  (Ollama gemma2:9b)
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ 4. MERGE        │  Склейка результатов без дублирования
│                 │
└────────┬────────┘
         │
         ▼
  CleanedTranscript (ожидание: ~60KB, ~15% reduction)
```

## Текущие параметры

| Параметр | Значение | Описание |
|----------|----------|----------|
| `CLEANER_MODEL` | gemma2:9b | Модель для очистки (env variable) |
| `CHUNK_SIZE_CHARS` | 3000 | Размер одной части |
| `CHUNK_OVERLAP_CHARS` | 200 | Перекрытие между частями |
| `SMALL_TEXT_THRESHOLD` | 3500 | Порог для включения chunking |
| `temperature` | 0.0 | Детерминированный вывод |

## Выбор модели

Модель `gemma2:9b` выбрана по результатам тестирования:

| Модель | Reduction на 3KB | Reduction на 6KB | Статус |
|--------|------------------|------------------|--------|
| gemma2:9b | 18.0% | 19.7% | ✅ Стабильна |
| mistral:7b-instruct | 18.4% | 71.4% | ❌ Нестабильна |
| phi3:14b | 48.1% | — | ❌ Суммаризирует |
| qwen2.5:14b | — | 85% | ❌ Суммаризирует |

**Критерии выбора:**
- Reduction 10-20% (не суммаризирует)
- Стабильность на разных размерах чанков
- Качество русского языка

---

## Глоссарий отдельно от LLM

- **Точность:** Глоссарий гарантирует правильное написание терминов
- **Скорость:** Regex быстрее LLM для простых замен
- **Контроль:** Централизованный словарь терминов

### Сортировка по длине

Вариации сортируются от длинных к коротким для избежания частичных замен:

```
Входной текст: "поговорим о гет тим"

Порядок замен:
1. "гет тим" → "GET Team" (длинная вариация)
2. "гет" → пропускается (уже обработано)

Результат: "поговорим о GET Team" ✓
```

## Chat API с system/user roles

Используем Chat API с разделением на роли:
- `system` — инструкции по очистке
- `user` — транскрипт для обработки

```python
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_template.format(transcript=chunk)},
]
result = await ai_client.chat(messages, model=settings.cleaner_model, temperature=0.0)
```

## Ожидаемые показатели

| Тип спикера | Сокращение | Примечание |
|-------------|------------|------------|
| Опытный | 5-10% | Подготовленное выступление |
| Средний | 10-15% | Вебинар, живое общение |
| Неопытный | 15-20% | Много запинок, техпроблемы |

**Важно:** Сокращение >25% означает возможную потерю контента. Сокращение >40% — скорее всего, LLM сделал саммари вместо очистки.

## Валидация результата

Сервис автоматически проверяет результат очистки:

```
INFO:  Cleaning complete: 47233 -> 40000 chars (15% reduction)  ← OK
WARN:  High reduction: 30% - possible content loss              ← Проверить
ERROR: Suspicious reduction: 85% - likely summarization         ← Баг!
```

## Тестирование

```bash
python -m backend.app.services.cleaner
```

Тесты проверяют: загрузку глоссария, замену терминов, загрузку промптов.

---

## Связанные файлы

- **Код:** [backend/app/services/cleaner.py](../../backend/app/services/cleaner.py)
- **System prompt:** [config/prompts/cleaner_system.md](../../config/prompts/cleaner_system.md)
- **User template:** [config/prompts/cleaner_user.md](../../config/prompts/cleaner_user.md)
- **Глоссарий:** [config/glossary.yaml](../../config/glossary.yaml)
- **AI клиент:** [backend/app/services/ai_client.py](../../backend/app/services/ai_client.py)
- **Исследование:** [docs/research/llm-transcript-cleaning-guide.md](../research/llm-transcript-cleaning-guide.md)
